{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Global imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Pandas initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.width', 1000)\n",
    "#pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Some constant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset'\n",
    "ZERO_VALUE = 'zero'\n",
    "NONE_VALUE = 'None'\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Train & test loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path(dataset_dir, 'train.csv'))\n",
    "test_df = pd.read_csv(Path(dataset_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As suggested by many participants, we remove several outliers\n",
    "train_df.drop(train_df[(train_df['OverallQual']<5) & (train_df['SalePrice']>200000)].index, inplace=True)\n",
    "train_df.drop(train_df[(train_df['GrLivArea']>4000) & (train_df['SalePrice']<300000)].index, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Log Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['SalePrice'] = np.log(train_df['SalePrice'])\n",
    "train_df[\"SalePrice\"] = np.log1p(train_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Concatenate train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457,)\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df['SalePrice']\n",
    "print(y_train.shape)\n",
    "train_ids = train_df['Id']\n",
    "test_ids = test_df['Id']\n",
    "\n",
    "train_df = train_df.drop(columns=['Id', 'SalePrice'])  # Dropping also the y_train values (already stored)\n",
    "test_df = test_df.drop(columns=['Id'])\n",
    "\n",
    "train_obs = train_df.shape[0]\n",
    "test_obs = test_df.shape[0]\n",
    "\n",
    "complete_df = pd.concat([train_df, test_df])  # Merge train and test dataframes to improve features ranges\n",
    "\n",
    "assert complete_df.shape[0] == train_obs + test_obs"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Trivial irrelevant features removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities has practically always the same value in the train dataset\n",
    "complete_df.drop(columns=['Utilities', 'Street'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Features grouping by NaN \"type\"/\"properties\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features = 77 | Features with NaN values = 33\nZero-like NaN features = 21 | None-like NaN features = 5 | NaN to MSC features = 5 | Other = 2\n"
     ]
    }
   ],
   "source": [
    "# Features with NaN values\n",
    "nan_mask = complete_df.isnull().any()\n",
    "nan_columns = nan_mask[nan_mask].shape[0]\n",
    "\n",
    "is_a_valid_feature = lambda x: x in complete_df\n",
    "# Feature with NaN values going to ZERO_VALUE\n",
    "# Those are features with categorical value, but with an intrinsic order so \"NaN\" (\"NA\") is the lower possible element.\n",
    "to_zero = list(filter(is_a_valid_feature, [\"PoolQC\",\n",
    "                                           \"Fence\",\n",
    "                                           \"FireplaceQu\",\n",
    "                                           'GarageFinish', 'GarageQual', 'GarageCond', 'GarageYrBlt', 'GarageArea',\n",
    "                                           'GarageCars',\n",
    "                                           'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'BsmtFullBath',\n",
    "                                           'BsmtHalfBath',\n",
    "                                           'BsmtQual', 'BsmtCond',\n",
    "                                           'BsmtExposure',  # TODO: mappa il valore No in 0 o 1\n",
    "                                           'BsmtFinType1', 'BsmtFinType2',  # TODO: da unire\n",
    "                                           'MasVnrArea']))\n",
    "\n",
    "# Features with NaN values going to NONE_VALUE.\n",
    "# Those are features with categorical value, but with no intrinsic order.\n",
    "to_none = list(filter(is_a_valid_feature,\n",
    "                      [\n",
    "                          'MSZoning',  # TODO: Maybe we should split this in sub-features with order\n",
    "                          \"MiscFeature\",\n",
    "                          \"Alley\",\n",
    "                          'GarageType',\n",
    "                          'MasVnrType'\n",
    "                      ]))\n",
    "\n",
    "# Features with NaN values going to the MSC one.\n",
    "# Those are features with unknown value and value property, so that they are mapped to the MSC value for that feature.\n",
    "to_most_common = list(filter(is_a_valid_feature, [\n",
    "    'Electrical',\n",
    "    'KitchenQual',\n",
    "    'Exterior1st',\n",
    "    'Exterior2nd',\n",
    "    'SaleType'\n",
    "]))\n",
    "\n",
    "other = list(filter(is_a_valid_feature, ['Functional', 'LotFrontage']))\n",
    "\n",
    "print('Features = {} | Features with NaN values = {}'.format(len(complete_df.keys()), nan_columns))\n",
    "print('Zero-like NaN features = {} | None-like NaN features = {} | NaN to MSC features = {} | Other = {}'\n",
    "      .format(len(to_zero), len(to_none), len(to_most_common), len(other)))\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "NaN removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457,)\n"
     ]
    }
   ],
   "source": [
    "for col in to_zero:\n",
    "    complete_df[col] = complete_df[col].fillna(ZERO_VALUE)\n",
    "\n",
    "for col in to_none:\n",
    "    complete_df[col] = complete_df[col].fillna(NONE_VALUE)\n",
    "\n",
    "for col in to_most_common:\n",
    "    complete_df[col] = complete_df[col].fillna(complete_df[col].mode()[0])\n",
    "\n",
    "# Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "complete_df[\"LotFrontage\"] = complete_df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "complete_df[\"Functional\"] = complete_df[\"Functional\"].fillna(\"Typ\")\n",
    "\n",
    "# Features with NaN values\n",
    "nan_mask = complete_df.isnull().any()\n",
    "nan_columns = nan_mask[nan_mask].shape[0]\n",
    "\n",
    "assert nan_columns == 0\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 1,
   "source": [
    "Features correlation search & removal (excluding NaN/null values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CORRELATION = 0.65\n",
    "# # Correlation map to see how features are correlated with SalePrice (ignori\n",
    "# corrmat = complete_df.corr()\n",
    "# corrmat = corrmat > CORRELATION\n",
    "# np.fill_diagonal(corrmat.values, False)\n",
    "# \n",
    "# print('Shape before removal: {}'.format(complete_df.shape))\n",
    "# removed = []\n",
    "# while any(corrmat.any()):\n",
    "#     for col in corrmat.keys():\n",
    "#         if corrmat[col].any():\n",
    "#             complete_df.drop(columns=[col], inplace=True)\n",
    "#             removed.append(col)\n",
    "#             break\n",
    "#     corrmat = complete_df.corr()\n",
    "#     corrmat = corrmat > CORRELATION\n",
    "#     np.fill_diagonal(corrmat.values, False)\n",
    "# print('Shape after removal: {}'.format(complete_df.shape))\n",
    "# print('Removed columns: {}'.format(removed))\n",
    "\n",
    "complete_df = complete_df.drop(columns= [\n",
    "    \"TotalBsmtSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"GarageYrBlt\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"PoolArea\",\n",
    "    \"3SsnPorch\",\n",
    "    \"MiscVal\",\n",
    "    \"MoSold\",\n",
    "    \"LowQualFinSF\",\n",
    "    \"HalfBath\",\n",
    "    \"FullBath\",\n",
    "    \"EnclosedPorch\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "Categories creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "     \n",
    "categorical_mapping = {\n",
    "    # Exterior material quality\n",
    "    \"ExterQual\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Present condition of the material on the exterior\n",
    "    \"ExterCond\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Height of the basement\n",
    "    \"BsmtQual\": [ZERO_VALUE, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # General condition of the basement\n",
    "    \"BsmtCond\": [ZERO_VALUE, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Walkout or garden level basement walls\n",
    "    \"BsmtExposure\": [ZERO_VALUE, 'No', 'Mn', 'Av', 'Gd'],\n",
    "    # Quality of basement finished area\n",
    "    \"BsmtFinType1\": [ZERO_VALUE, 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    # todo Quality of second finished area (if present)\n",
    "    \"BsmtFinType2\": [ZERO_VALUE, 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
    "    # Heating quality and condition\n",
    "    \"HeatingQC\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Kitchen quality\n",
    "    \"KitchenQual\": ['Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Home functionality rating\n",
    "    \"Functional\": ['Sal', 'Sev', 'Maj2', 'Maj1', 'Mod', 'Min2', 'Min1', 'Typ'],\n",
    "    # Fireplace quality\n",
    "    \"FireplaceQu\":  [ZERO_VALUE, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Interior finish of the garage\n",
    "    \"GarageFinish\": [ZERO_VALUE, 'Unf', 'RFn', 'Fin'],\n",
    "    # Garage quality\n",
    "    \"GarageQual\": [ZERO_VALUE, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Garage condition\n",
    "    \"GarageCond\": [ZERO_VALUE, 'Po', 'Fa', 'TA', 'Gd', 'Ex'],\n",
    "    # Pool quality\n",
    "    \"PoolQC\": [ZERO_VALUE, 'Fa', 'TA', 'Gd', 'Ex'],  \n",
    "    # Fence quality\n",
    "    \"Fence\": [ZERO_VALUE, 'MnWw', 'GdWo', 'MnPrv', 'GdPrv']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Categorical features mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (2916, 232)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-b362a39dda82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mcomplete_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (2916, 232)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# esegui solo una volta!!\n",
    "# if count == 0:\n",
    "#     for feature, categories in categorical_mapping.items():\n",
    "#         print(categories)\n",
    "#         complete_df[feature] = pd.Categorical(complete_df[feature], categories=categories).codes\n",
    "#     \n",
    "#     # Porta a zero -> 0 le feature solo numeriche\n",
    "#     complete_df = complete_df.replace(to_replace=ZERO_VALUE, value=0)\n",
    "#     \n",
    "#     print(complete_df[list(categorical_mapping.keys())].head())\n",
    "#     \n",
    "#     print('Da verificare per bene il funzionamento (ma credo sia corretto)')\n",
    "#     count +=1 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "complete_df = le.fit_transform(complete_df)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Features conversion (basic infer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.infer_objects()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Add some simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OpenPorchSF'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OpenPorchSF'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5c446efc2f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m complete_df['Total_porch_sf'] = (complete_df['OpenPorchSF'] + complete_df['3SsnPorch'] +\n\u001b[0;32m---> 15\u001b[0;31m                               \u001b[0mcomplete_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EnclosedPorch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcomplete_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ScreenPorch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                              complete_df['WoodDeckSF'])\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OpenPorchSF'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# #simplified features\n",
    "# # complete_df['haspool'] = complete_df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# # complete_df['has2ndfloor'] = complete_df['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# complete_df['hasgarage'] = complete_df['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# # complete_df['hasbsmt'] = complete_df['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# complete_df['hasfireplace'] = complete_df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# \n",
    "# # complete_df['Total_sqr_footage'] = (complete_df['BsmtFinSF1'] + complete_df['BsmtFinSF2'] +\n",
    "# #                                  complete_df['1stFlrSF'] + complete_df['2ndFlrSF'])\n",
    "# \n",
    "# # complete_df['Total_Bathrooms'] = (complete_df['FullBath'] + (0.5*complete_df['HalfBath']) + \n",
    "# #                                complete_df['BsmtFullBath'] + (0.5*complete_df['BsmtHalfBath']))\n",
    "# \n",
    "# complete_df['Total_porch_sf'] = (complete_df['OpenPorchSF'] + complete_df['3SsnPorch'] +\n",
    "#                               complete_df['EnclosedPorch'] + complete_df['ScreenPorch'] +\n",
    "#                              complete_df['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "One hot encoding of remaining categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature categoriche senza ordinamento\n",
    "to_one_hot_encoding = [\n",
    "    \"MSSubClass\",  # The building class\n",
    "    \"MSZoning\",  # The general zoning classification\n",
    "    \"Street\",  # Type of road access\n",
    "    \"Alley\",  # Type of alley access\n",
    "    \"LotShape\",  # General shape of property\n",
    "    \"LandContour\",  # Flatness of the property\n",
    "    \"LotConfig\",  # Lot configuration\n",
    "    \"LandSlope\",  # Slope of property\n",
    "    \"Neighborhood\",  # Physical locations within Ames city limits\n",
    "    \"Condition1\",  # Proximity to main road or railroad\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",  # Type of dwelling\n",
    "    \"HouseStyle\",  # Style of dwelling\n",
    "    \"RoofStyle\",  # Type of roof\n",
    "    \"RoofMatl\",  # Roof material\n",
    "    \"Exterior1st\",  # Exterior covering on house\n",
    "    \"Exterior2nd\",  # Exterior covering on house (if more than one material)\n",
    "    \"MasVnrType\",  # Masonry veneer type\n",
    "    \"Foundation\",  # Type of foundation\n",
    "    \"Heating\",  # Type of heating\n",
    "    \"CentralAir\",  # Central air conditioning\n",
    "    \"Electrical\",  # Electrical system\n",
    "    \"GarageType\",  # Garage location\n",
    "    \"PavedDrive\",  # Paved driveway\n",
    "    \"MiscFeature\",  # Miscellaneous feature not covered in other categories\n",
    "    \"MiscVal\",  # $Value of miscellaneous feature\n",
    "    \"SaleType\",  # Type of sale todo Forse va spezzata in altre feature\n",
    "    \"SaleCondition\"]  # Condition of sale\n",
    "complete_df = pd.get_dummies(complete_df, columns=list(filter(is_a_valid_feature, to_one_hot_encoding)))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "Regression!"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Validation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457, 232)\n(1457,)\n(1092, 232)\n(1092,)\n(365, 232)\n(365,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR on validation set: 0.12172446741291576\nDone validation\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "x_train = complete_df[:train_obs]\n",
    "x_test = complete_df[train_obs:]\n",
    "assert train_obs == x_train.shape[0]\n",
    "assert test_obs == x_test.shape[0]\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "x_reduced_train, x_validation, y_reduced_train, y_validation = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print(x_reduced_train.shape)\n",
    "\n",
    "\n",
    "print(y_reduced_train.shape)\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)\n",
    "# \n",
    "# predictor = make_pipeline(RobustScaler(),\n",
    "#                         XGBRegressor(learning_rate =0.01, n_estimators=3460, \n",
    "#                                      max_depth=3,min_child_weight=0 ,\n",
    "#                                      gamma=0, subsample=0.7,\n",
    "#                                      colsample_bytree=0.7,\n",
    "#                                      objective= 'reg:linear',nthread=4,\n",
    "#                                      scale_pos_weight=1,seed=27, \n",
    "#                                      reg_alpha=0.00006))\n",
    "\n",
    "\n",
    "predictor = make_pipeline(XGBRegressor(learning_rate =0.01, n_estimators=3460, \n",
    "                                     max_depth=3,min_child_weight=0 ,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective= 'reg:linear',nthread=4,\n",
    "                                     scale_pos_weight=1,seed=27, \n",
    "                                     reg_alpha=0.00006))\n",
    "\n",
    "# predictor = make_pipeline(RobustScaler(),\n",
    "#                           Lasso(alpha = 0.0003, random_state=1, max_iter=50000))\n",
    "\n",
    "predictor.fit(x_reduced_train, y_reduced_train)\n",
    "y_validation_pred = predictor.predict(x_validation)\n",
    "\n",
    "# y_validation_pred = np.expm1(y_validation_pred)\n",
    "\n",
    "# a = (filter(lambda  y: y <0, y_validation_pred))\n",
    "for i, l in enumerate(y_validation_pred[:]):\n",
    "    if l<0:\n",
    "        y_validation_pred[i] = 0\n",
    "        print(x_validation.iloc[i])\n",
    "# print(list(a))\n",
    "\n",
    "\n",
    "err = np.sqrt(mean_squared_log_error(y_validation, y_validation_pred))\n",
    "print(\"ERROR on validation set: {}\".format(err))\n",
    "\n",
    "print(\"Done validation\")"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457, 232)\n(1457,)\n(1092, 232)\n(1092,)\n(365, 232)\n(365,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR on validation set: 0.12172446741291576\nDone validation\n"
     ]
    }
   ],
   "source": [
    "predictor = make_pipeline(RobustScaler(),\n",
    "                        XGBRegressor(learning_rate =0.01, n_estimators=3460, \n",
    "                                     max_depth=3,min_child_weight=0 ,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective= 'reg:linear',nthread=4,\n",
    "                                     scale_pos_weight=1,seed=27, \n",
    "                                     reg_alpha=0.00006))\n",
    "predictor.fit(x_train, y_train)\n",
    "y_validation_pred = predictor.predict(x_validation)\n",
    "\n",
    "predictions = predictor.predict(x_test)\n",
    "result_df = pd.DataFrame()\n",
    "result_df['Id'] = test_ids\n",
    "result_df['SalePrice'] = predictions\n",
    "result_df.to_csv(Path(dataset_dir, 'predictions.csv'), index=False)\n",
    "# \n",
    "print(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
